{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install pyspark\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    " \n",
    "# Building the SparkSession and name \n",
    "# it :'pandas to spark'\n",
    "spark = SparkSession.builder.appName(\n",
    "  \"pandas to spark\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [[1, 2, '2016-03-01', 5], [1, 2, '2016-03-02', 6], [2, 3, '2017-06-25', 1], [3, 1, '2016-03-02', 0], [3, 4, '2018-07-03', 5]]\n",
    "activity = pd.DataFrame(data, columns=['player_id', 'device_id', 'event_date', 'games_played']).astype({'player_id':'Int64', 'device_id':'Int64', 'event_date':'datetime64[ns]', 'games_played':'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+\n",
      "|player_id|device_id|         event_date|games_played|\n",
      "+---------+---------+-------------------+------------+\n",
      "|        1|        2|2016-03-01 00:00:00|           5|\n",
      "|        1|        2|2016-03-02 00:00:00|           6|\n",
      "|        2|        3|2017-06-25 00:00:00|           1|\n",
      "|        3|        1|2016-03-02 00:00:00|           0|\n",
      "|        3|        4|2018-07-03 00:00:00|           5|\n",
      "+---------+---------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activity = spark.createDataFrame(activity)\n",
    "activity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|fraction|\n",
      "+--------+\n",
      "|    0.33|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lead, col, row_number, date_diff, when, sum, count, round\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "activity \\\n",
    ".withColumn('next_event_date', \n",
    "            lead(col('event_date'), 1) \\\n",
    "                    .over(Window.partitionBy('player_id') \\\n",
    "                                .orderBy('event_date'))) \\\n",
    ".withColumn('row_number', \n",
    "            row_number() \\\n",
    "                .over(Window.partitionBy('player_id') \\\n",
    "                                .orderBy('event_date'))) \\\n",
    ".withColumn('difference', date_diff(col('next_event_date'), col('event_date'))) \\\n",
    ".where('row_number == 1') \\\n",
    ".groupby('row_number') \\\n",
    ".agg(sum(when(col('difference') == 1, 1).otherwise(0)).alias('no_of_players'),\n",
    "     count(col('player_id')).alias('total_no_of_players')) \\\n",
    ".withColumn('fraction', round(col('no_of_players')/col('total_no_of_players'), 2)) \\\n",
    ".select('fraction') \\\n",
    ".show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "path",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
